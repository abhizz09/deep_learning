{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "df=datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining required variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt=df.data\n",
    "yt=df.target\n",
    "yt=pd.get_dummies(yt)\n",
    "yt=np.array(yt)\n",
    "#learning rate\n",
    "LR=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting the data into Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,x_test,y,y_test=train_test_split(xt,yt,test_size=.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise shapes \n",
    "dim=x.shape[1]\n",
    "dim\n",
    "dim2=x.shape[0]\n",
    "y.shape[1]\n",
    "m=x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of neurons in hidden layer 1\n",
    "hidden_layer1_perceptron=5\n",
    "#number of neurons in output layer\n",
    "op_layer_perceptron=y.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### describing shapes of hidden layer and out put layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=np.random.randn(hidden_layer1_perceptron,dim)*0.01                                                \n",
    "b1=np.zeros((hidden_layer1_perceptron,1))\n",
    "\n",
    "w_out=np.random.randn(op_layer_perceptron,hidden_layer1_perceptron)*0.01\n",
    "b_out=np.zeros((op_layer_perceptron,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(Z):\n",
    "    return np.maximum(0,Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sigmoid Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid (x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  differentiation of ReLU function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_activation_ReLU(x):\n",
    "    if x>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.829178266173762\n",
      "0.5787017107231269\n",
      "0.4372795929063516\n",
      "0.38054357356709284\n",
      "0.3531745467983329\n"
     ]
    }
   ],
   "source": [
    "#1st layer\n",
    "for i in range(5000):\n",
    "        #print(i)\n",
    "        z=np.dot(w1,x.T)\n",
    "        z=z+b1\n",
    "        A1=ReLU(z)\n",
    "\n",
    "\n",
    "        #out put layer\n",
    "\n",
    "        z2=np.dot(w_out,A1)\n",
    "        z2=z2+b_out\n",
    "        Y_OUT=sigmoid(z2)\n",
    "\n",
    "        cost=np.sum(np.multiply(y.T,np.log(Y_OUT)) + np.multiply((1-y.T),np.log(1-Y_OUT)))*(-1/m)\n",
    "        if i==100 or i==1000 or i==2000 or i==3000 or i==4000 or i==5000:\n",
    "            print(cost)\n",
    "\n",
    "        dz2=Y_OUT-y.T\n",
    "        dw2=(np.matmul(dz2,A1.T))*(1/m)\n",
    "        db2=np.sum(dz2,axis=1,keepdims=True)\n",
    "\n",
    "        diff_activation_HL1=np.ones((hidden_layer1_perceptron,m))\n",
    "        diff_activation_HL1.shape\n",
    "        for i in range(hidden_layer1_perceptron):\n",
    "            for j in range(m):\n",
    "                diff_activation_HL1[i,j]=diff_activation_ReLU(A1[i,j])\n",
    "\n",
    "        dz1=np.dot(w_out.T,dz2)*diff_activation_HL1\n",
    "        dw1=(1/m)*np.dot(dz1,x)\n",
    "        db=np.sum(dz1,axis=1,keepdims=True)\n",
    "        w1=w1-LR*dw1\n",
    "        b1=b1-LR*db\n",
    "        w_out=w_out-LR*dw2\n",
    "        b_out=b_out-LR*db2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
